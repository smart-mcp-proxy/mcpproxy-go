# MCP SDK Migration Analysis

## Current `github.com/mark3labs/mcp-go` usage in `mcpproxy`
- **Multi-transport clients.** The proxy spins up stdio, streamable HTTP, and SSE transports, each with custom wiring. Stdio creation depends on `uptransport.NewStdioWithOptions(..., uptransport.WithCommandFunc)` so the daemon can wrap commands, enforce working dirs, and track process groups (`internal/upstream/core/connection.go:309-360`). HTTP/SSE clients are built with `transport.NewStreamableHTTP`/`client.NewSSEMCPClient`, injecting arbitrary headers, bespoke `http.Client`s (no global timeout, logging transport), and optional OAuth stacks (`internal/transport/http.go:120-345`). SSE clients also rely on `client.OnConnectionLost` hooks to surface GOAWAY/GOLOSE events (`internal/upstream/core/connection.go:1147-1171`).
- **OAuth + token persistence.** The daemon generates complete OAuth configs (dynamic scope discovery, metadata endpoints, redirect hosts, PKCE), provisions shared token stores, and wires those into `client.NewOAuthStreamableHttpClient`/`client.NewOAuthSSEClient`. On auth challenges it leverages `client.IsOAuthAuthorizationRequiredError`, `client.GetOAuthHandler`, and helpers such as `GenerateCodeVerifier`, `GenerateState`, `TokenStore`, and `Token` structs to run PKCE + DCR flows and stash refresh tokens in BoltDB (`internal/transport/http.go:120-206`, `internal/oauth/config.go:317-385`, `internal/oauth/persistent_token_store.go:57-160`, `internal/upstream/core/connection.go:980-1105`, `1660-1760`).
- **Manual JSON-RPC lifecycle control.** The code expects a `client.Client` that can be constructed up-front, `Start`ed on a background context, `Close`d explicitly, and `Initialize`d manually to capture `InitializeResult` and emit tooling logs (`internal/upstream/core/connection.go:370-434`, `1408-1477`). Health monitoring calls `ListTools`/`CallTool` directly on that client (`internal/upstream/core/client.go:284-407`).
- **Server surface.** The proxy exposes its own MCP server using `mcpserver.NewMCPServer(..., mcpserver.WithToolCapabilities, mcpserver.WithRecovery)` and registers dozens of tools via `mcp.NewTool + mcp.With*` option builders (`internal/server/mcp.go:86-214`). Tool handlers return helper results such as `mcp.NewToolResultText`/`mcp.NewToolResultError` throughout the file (`internal/server/mcp.go:129-2091`).

## Official `github.com/modelcontextprotocol/go-sdk` capabilities
- **Client transports.** The SDK offers `mcp.CommandTransport` for stdio (you hand it a preconfigured `*exec.Cmd`), plus `mcp.StreamableClientTransport` and `mcp.SSEClientTransport` for HTTP (`tmp/go-sdk-official/mcp/cmd.go:1-60`, `tmp/go-sdk-official/mcp/streamable.go:1226-1294`, `tmp/go-sdk-official/mcp/sse.go:320-399`). These structs expose only `Endpoint`, optional `HTTPClient`, and retry counts—there are no first-class hooks for per-request headers, token injection, or tracing beyond what you can layer into a custom `http.Client`.
- **Client sessions.** `mcp.Client` encapsulates the initialize handshake; calling `client.Connect(ctx, transport, nil)` returns a `ClientSession` that you use for `ListTools`, `CallTool`, etc., but there is no separate `Start`, `OnConnectionLost`, or manual `Initialize` entry point (`tmp/go-sdk-official/mcp/client.go:100-210`, `560-640`).
- **Server API.** Servers are declared via `mcp.NewServer(impl, opts)` and populated with `mcp.AddTool`/`AddPrompt` plus generic handlers instead of the option-builder pattern. Capabilities such as “has tools/prompts” are toggled via `ServerOptions` flags rather than `WithToolCapabilities` (`tmp/go-sdk-official/mcp/server.go:1-140`, `tmp/go-sdk-official/mcp/tool.go:1-120`).
- **OAuth story.** The docs make clear that client-side OAuth currently means “bring your own `http.Client`” and that richer support is still pending (`tmp/go-sdk-official/docs/protocol.md:282-295`). There is a proof-of-concept `auth.HTTPTransport`, but it sits behind the `mcp_go_client_oauth` build tag, so it is excluded from normal builds and requires you to supply an `OAuthHandler` and manage the entire flow yourself (`tmp/go-sdk-official/auth/client.go:5-40`). The SDK does not ship equivalents for `client.OAuthConfig`, token stores, PKCE helpers, or callback servers.

## Gap summary
| Area | Present behavior in `mcpproxy` | State in official SDK | Impact |
| --- | --- | --- | --- |
| OAuth initiation & replay | Full-stack OAuth orchestration (scope discovery, PKCE, DCR, token storage, callback listeners, token refresh) driven by `client.OAuthConfig` + `TokenStore` (`internal/oauth/config.go:317-385`, `internal/oauth/persistent_token_store.go:57-160`, `internal/upstream/core/connection.go:1660-1760`). | No equivalent types; docs state OAuth must be handled by a custom `http.Client`, and optional helpers are hidden behind build tags (`tmp/go-sdk-official/docs/protocol.md:282-295`, `tmp/go-sdk-official/auth/client.go:5-37`). | **Blocking.** You would need to reimplement the entire OAuth client stack (including persistent stores and manual browser/login flows) before replacing the dependency. |
| Streamable/SSE headers & tracing | Relies on `transport.WithHTTPHeaders`, custom logging transports, and no-timeout SSE clients (`internal/transport/http.go:160-345`). | `StreamableClientTransport` / `SSEClientTransport` expose only an `HTTPClient`; no API for static headers or per-request instrumentation (`tmp/go-sdk-official/mcp/streamable.go:1226-1294`, `tmp/go-sdk-official/mcp/sse.go:320-399`). | Need to wrap every request via custom `http.RoundTripper` to replicate headers/logging. This is doable but requires additional plumbing (and still lacks obvious hooks for one-off headers like per-request OAuth tokens). |
| Connection lifecycle hooks | Code expects to `Start` transports manually, keep them alive via `context.Background()`, and receive `OnConnectionLost` callbacks for SSE (`internal/upstream/core/connection.go:370-375`, `1147-1155`). | Official client hides `Start`/`Initialize` inside `Client.Connect` and offers no connection-lost callback. | Requires refactoring of connection management, retry logic, and logging to the new session model. |
| Server tooling API | Uses `mcpserver.WithToolCapabilities`, `mcpserver.WithRecovery`, `mcp.NewTool` option builders, and helper result constructors across `internal/server/mcp.go`. | New server API expects `mcp.NewServer` + `mcp.AddTool` with typed handlers and no builder helpers (`tmp/go-sdk-official/mcp/server.go:1-140`, `tmp/go-sdk-official/mcp/tool.go:1-120`). | Every proxy tool definition would need to be rewritten (names, schemas, structured outputs, error helpers). Existing convenience functions like `mcp.NewToolResultText` do not exist. |
| Token store abstraction | Depends on `client.TokenStore` / `client.Token` interfaces for persistence and refresh decisions (`internal/oauth/persistent_token_store.go:57-160`). | No analogous interfaces exported; callers must invent their own storage and wire it into custom HTTP transports. | Requires recreating TokenStore contracts plus glue to share tokens across daemon/CLI. |

Other smaller deltas include reworking stdio launching (old code injects env/working-dir logic via `uptransport.WithCommandFunc`, while the new SDK expects callers to fabricate `*exec.Cmd` themselves) and replacing helper APIs (`client.NewOAuthStreamableHttpClient`, `client.NewMemoryTokenStore`, `client.IsOAuthAuthorizationRequiredError`, etc.) that simply do not exist in the official tree.

## Can the official SDK connect to arbitrary OAuth servers today?
Not without substantial custom code. The maintainers explicitly note that “Client-side OAuth is implemented by setting `StreamableClientTransport.HTTPClient` to a custom `http.Client`. Additional support is forthcoming… At present we don't provide client-side OAuth support.” (`tmp/go-sdk-official/docs/protocol.md:282-295`). The only OAuth helper in the repo (`auth.HTTPTransport`) is gated behind the `mcp_go_client_oauth` build tag (`tmp/go-sdk-official/auth/client.go:5-37`), is never referenced elsewhere, and still requires the caller to implement the handler that drives discovery, PKCE, browser flows, and token persistence. There is no equivalent to `client.OAuthConfig`, no token-store abstraction, and no built-in callback orchestration. Therefore the official SDK does **not** yet provide an out-of-the-box way to connect to arbitrary OAuth 2.1 servers the way `mcp-go` does; you'd need to replicate that machinery yourself before switching.

## Recommendations
1. **Treat OAuth as the critical blocker.** Porting would require designing a new OAuth module (scope discovery, metadata fetch, dynamic registration, PKCE, persistent tokens, callback HTTP server) atop the generic HTTP transport hooks the official SDK exposes.
2. **Prototype a compatibility layer first.** Wrap `mcp.Client` into an internal interface that mimics the current `client.Client` (`Start`, `Initialize`, `CallTool`, `OnConnectionLost`) so the rest of the runtime can switch incrementally while you rebuild transports on top of `CommandTransport` / `StreamableClientTransport`.
3. **Schedule a full server rewrite.** Moving from `mcpserver` to the new `mcp` server API means converting every tool definition and result helper; plan that as a separate workstream once client-side gaps are closed.
4. **Delay dependency swap until OAuth story stabilizes upstream.** Keep an eye on modelcontextprotocol/go-sdk#493 (referenced in their docs) so you can reassess once official OAuth support lands; re-evaluate when the SDK exports first-class token/config helpers.

## Why “just implement a Go version of mcp-remote” is not realistic today

`mcp-remote` (TypeScript) piggybacks on the Node ecosystem (`openid-client`, Electron-style browser automation, etc.) to handle every step of the OAuth 2.1 journey: dynamic client registration, PKCE, token persistence, local callback servers, OS-specific browser launching, and refresh logic. Recreating that inside the Go tray/daemon would require a comparable foundation that simply doesn’t exist yet:

- **No client-side OAuth hooks in the official Go SDK.** `github.com/modelcontextprotocol/go-sdk` explicitly says “client-side OAuth is implemented by setting `StreamableClientTransport.HTTPClient` to a custom `http.Client` … we don’t provide client-side OAuth support” (`docs/protocol.md:282-295`). There are no equivalents of `client.OAuthConfig`, token stores, helper callbacks, or the `IsOAuthAuthorizationRequiredError` machinery we rely on today, so a Go implementation would be starting from bare HTTP primitives.

- **Missing cross-platform plumbing.** mcpproxy runs as a long-lived daemon (launchd, systemd, Windows service) that may not have a GUI session. Spawning browsers, binding callback ports, and storing per-user tokens—steps that `mcp-remote` can take for granted in a foreground CLI—would require new privilege separation, user-session detection, and secure storage layers in Go. Without that, an “automatic OAuth flow” would fail for most tray installs.

- **Server-by-server variability.** “Any MCP server” can mean Okta, Azure AD, GitHub, Cloudflare, bespoke OAuth 2.1 implementations, or even non-OIDC providers. They differ in metadata endpoints, DCR capabilities, grant types, refresh semantics, and required scopes. Delivering a blanket Go solution would force us to encode every provider’s quirks (or re-expose client IDs/secrets back to the user), defeating the goal of “no extra config”.

- **Release + maintenance burden.** Shipping our own OAuth stack would make mcpproxy responsible for every security edge case (PKCE entropy, state replay, token cache encryption, auto-refresh, rate limiting, headless fallbacks) on three OSes. That is more than just wiring a library; it’s a new product surface that we would need to audit and support, without official SDK backing.

Until the official Go SDK grows first-class OAuth constructs—or we’re willing to own the entire OAuth surface area ourselves—it’s safer to keep treating remote OAuth flows as an external responsibility (e.g., via purpose-built proxies or the existing Node-based helpers) rather than promising a built-in Go client that “just works for any server.”
